{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/jupyter/root/ECNU/DataMining/L18-ImageObjectRecogDL\n"
     ]
    }
   ],
   "source": [
    "%cd /data/jupyter/root/ECNU/DataMining/L18-ImageObjectRecogDL/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os, sys\n",
    "\n",
    "# 启动绘图\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import codecs\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手写数字识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    def __init__(self):\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "        \n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        \n",
    "        image_dir =os.listdir('data/trainingDigits')\n",
    "        for image_file_name in image_dir:\n",
    "            image = []\n",
    "            image_file_path = os.path.join('data/trainingDigits', image_file_name)\n",
    "            fr = open(image_file_path)\n",
    "            \n",
    "            for line in fr.readlines():\n",
    "                line = line.strip()\n",
    "                list_line = []\n",
    "                for i in range(32):\n",
    "                    list_line.append(int(line[i]))\n",
    "                image.append(list_line)\n",
    "            train_x.append(np.asarray(image))\n",
    "            label = np.zeros(10)\n",
    "            label[int(image_file_name.split('_')[0])] = 10\n",
    "            train_y.append(label)\n",
    "        self.train_images = train_x\n",
    "        self.train_labels = train_y\n",
    "        # 混淆数据\n",
    "        data = list(zip(self.train_images, self.train_labels))\n",
    "        random.shuffle(data)\n",
    "        self.train_images[:], self.train_labels[:] = zip(*data)\n",
    "        \n",
    "        self._num_examples = len(self.train_images)\n",
    "        \n",
    "    def batch_inter(self, batch_size):\n",
    "        self._num_examples = len(self.train_images)\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        \n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            self._epochs_completed += 1\n",
    "            data = list(zip(self.train_images, self.train_labels))\n",
    "            random.shuffle(data)\n",
    "            self.train_images[:], self.train_labels[:] = zip(*data)\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_sizea <= selflf._num_examples\n",
    "        end = self._index_in_epoch\n",
    "        return self.train_images[start:end], self.train_labels[start:end]\n",
    "    \n",
    "    def test_data(self):\n",
    "        test_x = []\n",
    "        test_y = []\n",
    "        \n",
    "        image_dir =os.listdir('data/testDigits')\n",
    "        for image_file_name in image_dir:\n",
    "            image = []\n",
    "            image_file_path = os.path.join('data/testDigits', image_file_name)\n",
    "            fr = open(image_file_path)\n",
    "            for line in fr.readlines():\n",
    "                line = line.strip()\n",
    "                list_line = []\n",
    "                for i in range(32):\n",
    "                    list_line.append(int(line[i]))\n",
    "                image.append(list_line)\n",
    "            test_x.append(np.asarray(image))\n",
    "            label = np.zeros(10)\n",
    "            label[int(image_file_name.split('_')[0])] = 10\n",
    "            test_y.append(label)\n",
    "        self.test_images = test_x\n",
    "        self.test_labels = test_y\n",
    "        # 混淆数据\n",
    "        data = list(zip(self.test_images, self.test_labels))\n",
    "        random.shuffle(data)\n",
    "        self.test_images[:], self.test_labels[:] = zip(*data)\n",
    "        return self.test_images, self.test_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._num_examples\n",
    "data = Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class Model_CNN_digit(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        def weight_variable(shape):\n",
    "            initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "            return tf.Variable(initial)\n",
    "        def bias_variable(shape):\n",
    "            initial = tf.constant(0.1, shape=shape)\n",
    "            return tf.Variable(initial)\n",
    "        # 卷积层\n",
    "        def conv2d(x, W):\n",
    "            return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        # 池化层\n",
    "        def max_pool_2x2(x):\n",
    "            return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        x = tf.placeholder(tf.float32, [None, 32, 32])\n",
    "        y = tf.placeholder(tf.float32, [None, 10])\n",
    "        x_image = tf.reshape(x, [-1, 32, 32, 1])\n",
    "\n",
    "        # 第一个卷积层\n",
    "        W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        # 使用conv2d 进行卷积\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "        # 第二个卷积层\n",
    "        W_conv2 = weight_variable([5, 5, 1, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        # 使用conv2d 进行卷积\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "        # 全连接层\n",
    "        W_fcl = weight_variable([8 * 8 * 64, 1024])\n",
    "        b_fcl = bias_variable([1024])\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 8 * 8* 64])\n",
    "        h_fcl = tf.nn.relu(tf.matmul(h_pool2_flat, W_fcl) + b_fcl)\n",
    "\n",
    "        # 减轻过拟合\n",
    "        h_fcl_drop = tf.nn.dropout(h_fcl, keep_prob=0.75)\n",
    "\n",
    "        W_fc2 = weight_variable([1024, 10])\n",
    "        b_fc2 = bias_variable([10])\n",
    "        pred = tf.nn.softmax(tf.matmul(h_fcl_drop, W_fc2) + b_fc2)\n",
    "\n",
    "        cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred), reduction_indices=1))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "        correct_predicion = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predicion, tf.float32))\n",
    "\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.pred = pred\n",
    "        self.cost = cost\n",
    "        self.accuracy = accuracy\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train_model(self, sess, batch_xs, batch_ys):\n",
    "        feed_dict ={\n",
    "            self.x: batch_xs,\n",
    "            self.y: batch_ys\n",
    "        }\n",
    "        to_return = {\n",
    "            'train_op': self.optimizer,\n",
    "            'loss': self.cost,\n",
    "            'acc': self.accuracy,\n",
    "        }\n",
    "        return sess.run(to_return, feed_dict)\n",
    "\n",
    "\n",
    "    def test_model(self, sess, batch_xs):\n",
    "        feed_dict = {\n",
    "            self.x: batch_xs\n",
    "        }\n",
    "        to_return = {\n",
    "            'pred': self.pred\n",
    "        }\n",
    "        return sess.run(to_return, feed_dict)\n",
    "    def eval_mode(self, sess, batch_xs, batch_ys):\n",
    "        correct_predicion = tf.equal(tf.argmax(self.pred, 1), tf.argmax(self.y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predicion, tf.float32))\n",
    "\n",
    "        feed_dict ={\n",
    "            self.x: batch_xs,\n",
    "            self.y: batch_ys\n",
    "        }\n",
    "        to_return = {\n",
    "            'acc': accuracy\n",
    "        }\n",
    "        return sess.run(to_return, feed_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "training_epochs = 50\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "keep_prob = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_CNN_digit()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-02fca5e507ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_xs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-dc28e6772934>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, sess, batch_xs, batch_ys)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;34m'acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         }\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_return\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "batch_xs, batch_ys = data.batch_inter(batch_size)\n",
    "print(batch_xs[0])\n",
    "print(batch_ys[0])\n",
    "results = model.train_model(sess, batch_xs , batch_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "input and filter must have the same depth: 32 vs 1\n\t [[node Conv2D_3 (defined at /root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'Conv2D_3':\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-eb3ce018b338>\", line 1, in <module>\n    model = Model_CNN_digit()\n  File \"<ipython-input-13-dc28e6772934>\", line 33, in __init__\n    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n  File \"<ipython-input-13-dc28e6772934>\", line 13, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 2010, in conv2d\n    name=name)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: input and filter must have the same depth: 32 vs 1\n\t [[{{node Conv2D_3}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1c3e506125a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_xs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-dc28e6772934>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, sess, batch_xs, batch_ys)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;34m'acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         }\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_return\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: input and filter must have the same depth: 32 vs 1\n\t [[node Conv2D_3 (defined at /root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'Conv2D_3':\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-eb3ce018b338>\", line 1, in <module>\n    model = Model_CNN_digit()\n  File \"<ipython-input-13-dc28e6772934>\", line 33, in __init__\n    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n  File \"<ipython-input-13-dc28e6772934>\", line 13, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 2010, in conv2d\n    name=name)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/root/anaconda3/envs/DataMining/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cos = 0.\n",
    "        avg_cos_list = []\n",
    "        avg_acc = 0.\n",
    "        total_batch = int(len(data) / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = data.batch_inter(batch_size)\n",
    "            print(batch_xs[0][0])\n",
    "            print(batch_ys[0])\n",
    "            results = model.train_model(sess, batch_xs , batch_ys)\n",
    "            c = results['loss']\n",
    "            ac = results['acc']\n",
    "            \n",
    "            avg_cos_list.append(c)\n",
    "            \n",
    "            avg_cos += c/total_batch\n",
    "            avg_acc += ac/total_batch\n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            print(\"CNN Epoch\", '%04d'%(epoch+1), \n",
    "                  \"cost=\", \"{:.9f}\".format(avg_cos), \n",
    "                  \"accuracy\",\"{:.9f}\".formato(avg_acc))\n",
    "    print(\"finished\")\n",
    "    \n",
    "    test_xs, test_ys = data.test_data()\n",
    "    acc = model.eval_model(sess, test_xs, test_ys)\n",
    "    print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "datamining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
